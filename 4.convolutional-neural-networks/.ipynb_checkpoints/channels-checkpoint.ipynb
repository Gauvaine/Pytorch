{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6025eb9",
   "metadata": {},
   "source": [
    "# 多输入多输出通道\n",
    "\n",
    "## 多输入通道\n",
    "\n",
    "当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。  \n",
    "(**实现一下多输入通道互相关运算**)。  \n",
    "简而言之，就是对每个通道执行互相关操作，然后将结果相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d263f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "    # zip () 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b100f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2*3*3\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bb144",
   "metadata": {},
   "source": [
    "## 多输出通道\n",
    "在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，可以将每个通道看作对不同特征的响应。  \n",
    "实现[**计算多个通道的输出的互相关函数**]。  \n",
    "在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac801e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    # torch.stack函数会返回一个新的张量，其中的每个元素都是输入张量中对应位置的元素堆叠而成的。新张量的维度会增加一个维度，该维度的大小等于输入张量的个数。\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2811b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1.],\n",
       "          [2., 3.]],\n",
       "\n",
       "         [[1., 2.],\n",
       "          [3., 4.]]],\n",
       "\n",
       "\n",
       "        [[[1., 2.],\n",
       "          [3., 4.]],\n",
       "\n",
       "         [[2., 3.],\n",
       "          [4., 5.]]],\n",
       "\n",
       "\n",
       "        [[[2., 3.],\n",
       "          [4., 5.]],\n",
       "\n",
       "         [[3., 4.],\n",
       "          [5., 6.]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "# K.shape:torch.Size([3, 2, 2, 2])\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e163f660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec7ea6",
   "metadata": {},
   "source": [
    "# 1x1卷积层\n",
    "$1 \\times 1$卷积，即$k_h = k_w = 1$\n",
    "因为使用了最小窗口，$1\\times 1$卷积失去了卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。\n",
    "其实$1\\times 1$卷积的唯一计算发生在通道上。  \n",
    " :numref:`fig_conv_1x1`展示了使用$1\\times 1$卷积核与$3$个输入通道和$2$个输出通道的互相关计算。\n",
    "这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。\n",
    "我们可以将$1\\times 1$卷积层看作在每个像素位置应用的全连接层，以$c_i$个输入值转换为$c_o$个输出值。\n",
    "因为这仍然是一个卷积层，所以跨像素的权重是一致的。同时，$1\\times 1$卷积层需要的权重维度为$c_o\\times c_i$，再额外加上一个偏置。  \n",
    "![互相关计算使用了具有3个输入通道和2个输出通道的 $1\\times 1$ 卷积核。其中，输入和输出具有相同的高度和宽度。](../img/conv-1x1.svg)\n",
    ":label:`fig_conv_1x1`  \n",
    "下面使用全连接层实现$1 \\times 1$卷积。请注意，需要对输入和输出的数据形状进行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079d80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # 全连接层中的矩阵乘法\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916b043",
   "metadata": {},
   "source": [
    "当执行$1\\times 1$卷积运算时，上述函数相当于先前实现的互相关函数`corr2d_multi_in_out`。下面用一些样本数据来验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e27b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True],\n",
       "         [True, True, True],\n",
       "         [True, True, True]],\n",
       "\n",
       "        [[True, True, True],\n",
       "         [True, True, True],\n",
       "         [True, True, True]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "Y1==Y2\n",
    "# assert float(torch.abs(Y1 - Y2).sum()) < 1e-6 感觉不需要，就是矩阵位置的变化，值并没有改变，所以可以直接判断是否相等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47244691",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 多输入多输出通道可以用来扩展卷积层的模型。\n",
    "* 当以每像素为基础应用时，$1\\times 1$卷积层相当于全连接层。\n",
    "* $1\\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。\n",
    "\n",
    "**zip () 函数**：用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。  \n",
    "**torch.stack函数**：会返回一个新的张量，其中的每个元素都是输入张量中对应位置的元素堆叠而成的。新张量的维度会增加一个维度，该维度的大小等于输入张量的个数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
