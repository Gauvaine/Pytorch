{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ade234",
   "metadata": {},
   "source": [
    "# 实战 Kaggle 比赛：图像分类 (CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e911176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebfd6b6",
   "metadata": {},
   "source": [
    "## 获取并组织数据集\n",
    "比赛数据集分为训练集和测试集，其中训练集包含50000张、测试集包含300000张图像。在测试集中，10000张图像将被用于评估，而剩下的290000张图像将不会被进行评估，包含它们只是为了防止手动标记测试集并提交标记结果。  \n",
    "两个数据集中的图像都是png格式，高度和宽度均为32像素并有三个颜色通道（RGB）。  \n",
    "这些图片共涵盖10个类别：飞机、汽车、鸟类、猫、鹿、狗、青蛙、马、船和卡车。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03b7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "# d2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip','2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n",
    "\n",
    "# 如果使用完整的Kaggle竞赛的数据集，设置demo为False\n",
    "# demo = True\n",
    "\n",
    "# if demo:\n",
    "#     data_dir = d2l.download_extract('cifar10_tiny')\n",
    "# else:\n",
    "#     data_dir = '../data/cifar-10/'\n",
    "data_dir = './data/cifar10_tiny/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75445b2",
   "metadata": {},
   "source": [
    "## 整理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aee2873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 训练样本 : 1000\n",
      "# 类别 : 10\n"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "def read_csv_labels(fname):\n",
    "    \"\"\"读取fname来给标签字典返回一个文件名\"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        # 跳过文件头行(列名)\n",
    "        lines = f.readlines()[1:]\n",
    "    tokens = [l.rstrip().split(',') for l in lines]\n",
    "    return dict(((name, label) for name, label in tokens))\n",
    "\n",
    "labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
    "print('# 训练样本 :', len(labels))\n",
    "print('# 类别 :', len(set(labels.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da6828b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def copyfile(filename, target_dir):\n",
    "    \"\"\"将文件复制到目标目录\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    shutil.copy(filename, target_dir)\n",
    "\n",
    "#@save\n",
    "def reorg_train_valid(data_dir, labels, valid_ratio):\n",
    "    \"\"\"将验证集从原始的训练集中拆分出来\"\"\"\n",
    "    # 训练数据集中样本最少的类别中的样本数\n",
    "    n = collections.Counter(labels.values()).most_common()[-1][1]\n",
    "    # 验证集中每个类别的样本数\n",
    "    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
    "    label_count = {}\n",
    "    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n",
    "        label = labels[train_file.split('.')[0]] # label为类别名如car\n",
    "        fname = os.path.join(data_dir, 'train', train_file)\n",
    "        copyfile(fname, os.path.join(data_dir, 'train_valid_test','train_valid', label))\n",
    "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
    "            copyfile(fname, os.path.join(data_dir, 'train_valid_test','valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            copyfile(fname, os.path.join(data_dir, 'train_valid_test','train', label))\n",
    "    return n_valid_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66140fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def reorg_test(data_dir):\n",
    "    \"\"\"在预测期间整理测试集，以方便读取\"\"\"\n",
    "    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n",
    "        copyfile(os.path.join(data_dir, 'test', test_file),\n",
    "                 os.path.join(data_dir, 'train_valid_test', 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ded0138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorg_cifar10_data(data_dir, valid_ratio):\n",
    "    labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
    "    reorg_train_valid(data_dir, labels, valid_ratio)\n",
    "    reorg_test(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6d62b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 if demo else 128\n",
    "valid_ratio = 0.1\n",
    "reorg_cifar10_data(data_dir, valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803f336",
   "metadata": {},
   "source": [
    "## 图像增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cab31e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    # 在高度和宽度上将图像放大到40像素的正方形\n",
    "    torchvision.transforms.Resize(40),\n",
    "    # 随机裁剪出一个高度和宽度均为40像素的正方形图像，\n",
    "    # 生成一个面积为原始图像面积0.64～1倍的小正方形，\n",
    "    # 然后将其缩放为高度和宽度均为32像素的正方形\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),\n",
    "                                                   ratio=(1.0, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # 标准化图像的每个通道\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                     [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                     [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f976b",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e102a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.datasets.ImageFolder 类自动处理图像数据集的标签。\n",
    "# 具体来说，ImageFolder 会从指定目录结构中推断出每张图像的标签。标签是根据子文件夹的名称生成的。\n",
    "# 并且，标签会自动转变为类别编号，而不是子文件夹的名称。\n",
    "# 如果需要将这些整数标签转换回子文件夹的名称，可以使用 ImageFolder 对象的 classes 属性，该属性包含类别名称的列表，索引与标签对应。\n",
    "train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train_valid_test', folder),\n",
    "    transform=transform_train) for folder in ['train', 'train_valid']]\n",
    "\n",
    "valid_ds, test_ds = [torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train_valid_test', folder),\n",
    "    transform=transform_test) for folder in ['valid', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a798d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [torch.utils.data.DataLoader(dataset, batch_size, shuffle=True, drop_last=True)\n",
    "    for dataset in (train_ds, train_valid_ds)]\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423cbd89",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c90a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    num_classes = 10\n",
    "    net = d2l.resnet18(num_classes, 3)\n",
    "    return net\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff652249",
   "metadata": {},
   "source": [
    "## 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "118d4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim.lr_scheduler.StepLR 是 PyTorch 中的学习率调度器之一，它实现了每个给定数量的epoch后将学习率降低一个给定的因子。\n",
    "# optimizer：传入优化器对象，如 torch.optim.SGD 或 torch.optim.Adam。\n",
    "# step_size：学习率下降的周期，即经过多少个epoch后降低学习率。\n",
    "# gamma：学习率衰减因子，即学习率下降的幅度。\n",
    "# 如每5个epoch后，StepLR 调度器会将 trainer 优化器的学习率乘以0.1。这将持续下去，直到训练完成或者调度器被停止。\n",
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay):\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    legend = ['train loss', 'train acc']\n",
    "    if valid_iter is not None:\n",
    "        legend.append('valid acc')\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],legend=legend)\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = d2l.train_batch_ch13(net, features, labels,loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0])\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,(metric[0] / metric[2], metric[1] / metric[2], None))\n",
    "        if valid_iter is not None:\n",
    "            valid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter)\n",
    "            animator.add(epoch + 1, (None, None, valid_acc))\n",
    "        scheduler.step()\n",
    "    measures = (f'train loss {metric[0] / metric[2]:.3f}, '\n",
    "                f'train acc {metric[1] / metric[2]:.3f}')\n",
    "    if valid_iter is not None:\n",
    "        measures += f', valid acc {valid_acc:.3f}'\n",
    "    print(measures + f'\\n{metric[2] * num_epochs / timer.sum():.1f}'\n",
    "          f' examples/sec on {str(devices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec578654",
   "metadata": {},
   "source": [
    "## 训练和验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices, num_epochs, lr, wd = d2l.try_all_gpus(), 20, 2e-4, 5e-4\n",
    "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
    "train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adac06d3",
   "metadata": {},
   "source": [
    "## 在 Kaggle 上对测试集进行分类并提交结果\n",
    "在获得具有超参数的满意的模型后，我们使用所有标记的数据（包括验证集）来重新训练模型并对测试集进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97439c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, preds = get_net(), []\n",
    "train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period, lr_decay)\n",
    "\n",
    "for X, _ in test_iter:\n",
    "    y_hat = net(X.to(devices[0]))\n",
    "    preds.extend(y_hat.argmax(dim=1).type(torch.int32).cpu().numpy())\n",
    "sorted_ids = list(range(1, len(test_ds) + 1))\n",
    "sorted_ids.sort(key=lambda x: str(x))\n",
    "df = pd.DataFrame({'id': sorted_ids, 'label': preds})\n",
    "df['label'] = df['label'].apply(lambda x: train_valid_ds.classes[x])\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
